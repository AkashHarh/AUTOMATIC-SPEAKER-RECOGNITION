Speaker Recognition(SR), which combines Speaker Identification
(SI) and Speaker Verification (SV), a variety of features and techniques have
been developed over the previous 60 years for SR. Automatic speaker
recognition (ASR), also referred to as vocal biometric recognition, is one
method of human biometric identification. Automatic speech recognition plays
such a crucial part in so many applications,including voice assistants,
transcription services, and more,it has attracted a lot of attention lately. This
paper develops an Automatic SR system. The framework is based on the
integration of Gated Recurrent Units in Recurrent Neural Networks (RNN -
GRU) with Connectionist Temporal Classification (CTC) loss via the layers of
a 2D Convolutional Neural Network (2D-CNN). Using the benchmark
LJspeech dataset, the model has been evaluated. The primary performance
metric, Error Rate (ER), is a key focus. The achieved ER rates of 16%-17% for
20 epochs underscore the promising progress in automatic SR technology,
setting the stage for continued advancements in this field.
